{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Larger, Smaller]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Larger, Smaller]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "import prioritizing\n",
    "\n",
    "membGeomFile = open(\"member_geometry.txt\", \"r\")\n",
    "membForcesFile = open(\"SAP_O_MemberForce.txt\", \"r\")\n",
    "continConsFile = open(\"continuity_constraints_list.txt\", \"r\")\n",
    "hierConsFile = open(\"hierarchical_constraints_list.txt\", \"r\")\n",
    "\n",
    "'''\n",
    "we should list out all the global variables\n",
    "everything should communicated through index of (HSS406.4X406.4X15.9) or member_id, besides the binary search\n",
    "The sections infomation will be proccessed by ascending first\n",
    "'''\n",
    "global Fy,K,E\n",
    "global sec_info,mem_info,mem_info_compacted\n",
    "global active_member_list\n",
    "global graph_children,graph_parents,priority_list\n",
    "global cs\n",
    "global continuity_list,cycle_list\n",
    "global continuity_root,cycle_root\n",
    "global num_all_sec\n",
    "\n",
    "\n",
    "Fy=345;\n",
    "E=200000;\n",
    "K=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Merging and Remapping -- Continuity and Cycles in the tree\n",
    "# \n",
    "# This part include two functions: \n",
    "# * merging_and_removing_constraint:Replace the  orginal vertex with the root vertex in the merging_root, and generate a condensed tree\n",
    "# * mapping_back_group:Map the vertex from condensed tree to the orginial tree\n",
    "\n",
    "\n",
    "\n",
    "def merging_and_removing_constraint(cons_pair,merging_root):\n",
    "    for i in cons_pair.index:\n",
    "        if cons_pair.Larger[i] in merging_root:\n",
    "            cons_pair.Larger[i]=merging_root[cons_pair.Larger[i]]\n",
    "            \n",
    "        if cons_pair.Smaller[i] in merging_root:\n",
    "            cons_pair.Smaller[i]=merging_root[cons_pair.Smaller[i]]\n",
    "        \n",
    "        if cons_pair.Smaller[i]==cons_pair.Larger[i]:\n",
    "            cons_pair.Smaller[i]=''\n",
    "            cons_pair.Larger[i]=''\n",
    "            \n",
    "    cons_pair=cons_pair[cons_pair.Smaller!='']\n",
    "    return cons_pair.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "def mapping_back_group(merging_list):\n",
    "    global cs\n",
    "    for root in merging_list:\n",
    "        for mem_id in merging_list[root]:\n",
    "            if (mem_id not in cs.index) and (mem_id not in active_member_list):\n",
    "                sec=cs.cross_section[root]\n",
    "                (f,pc,mcx,mcy,util)=check_feasibility(mem_id,sec,2)\n",
    "                cs_new=pd.DataFrame({'member_ID':mem_id,'cross_section':sec,'feasibility':f,'Pc':pc,'Mcx':mcx,'Mcy':mcy,'util':util},index=[mem_id]).set_index('member_ID')\n",
    "                cs=cs.append(cs_new) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#  FUNCTION -- check the feasibility\n",
    "def check_feasibility(mem_id,sec,flag):\n",
    "    global sec_info,mem_info,mem_info_compacted\n",
    "    global Fy,E,K\n",
    "    \n",
    "    if flag==1: # for the compacted check\n",
    "        pr=mem_info_compacted.P[mem_id]\n",
    "        mrx=mem_info_compacted.Mx[mem_id]\n",
    "        mry=mem_info_compacted.My[mem_id]\n",
    "        l=mem_info_compacted.L[mem_id]\n",
    "    elif flag==2: # for mapping back\n",
    "        pr=abs(mem_info.P[mem_id])\n",
    "        mrx=abs(mem_info.Mx[mem_id])\n",
    "        mry=abs(mem_info.My[mem_id])\n",
    "        l=abs(mem_info.L[mem_id])\n",
    "    elif flag==3: # for mapping back\n",
    "        mem_id=mem_info.index[mem_id]\n",
    "        pr=abs(mem_info.P[mem_id])\n",
    "        mrx=abs(mem_info.Mx[mem_id])\n",
    "        mry=abs(mem_info.My[mem_id])\n",
    "        l=abs(mem_info.member_length[mem_id])\n",
    "        \n",
    "    # Round HSS Feasibility    \n",
    "    if sec[0] == (\"H\"):  \n",
    "        A=sec_info[\"HSS\"].A[sec]\n",
    "        I=sec_info[\"HSS\"].I[sec]\n",
    "        Z=sec_info[\"HSS\"].Z[sec]\n",
    "        D=sec_info[\"HSS\"].D[sec]\n",
    "        S=sec_info[\"HSS\"].S[sec]\n",
    "        d_t=sec_info[\"HSS\"].d_t[sec]\n",
    "        r = sec_info[\"HSS\"].r[sec]\n",
    "    \n",
    "        # Pc\n",
    "        Q = 1.0\n",
    "        if sec_info[\"HSS\"].C_s[sec] == \"S\":\n",
    "            Q = 0.038*E/(Fy*d_t) + 2/3\n",
    "            \n",
    "        fe=np.pi**2*E/(K*l/r)**2\n",
    "        if (Q*Fy/fe)<=2.25:\n",
    "            fcr=Q*Fy*[0.658]**(Q*Fy/fe)\n",
    "        else:\n",
    "            fcr=0.877*fe\n",
    "        pc=(fcr*A)*0.9\n",
    "    \n",
    "        # Mcx & Mcy\n",
    "        if sec_info[\"HSS\"].F_s[sec] == \"C\":\n",
    "            mcx = mcy = 0.9*Z*Fy\n",
    "        elif sec_info[\"HSS\"].F_s[sec] == \"NC\":\n",
    "            mcx = mcy = 0.9* min(Z*Fy, (0.021*E/d_t + Fy)*S)      \n",
    "        elif sec_info[\"HSS\"].F_s[sec] == \"S\":\n",
    "            mcx = mcy = 0.9* min (Z*Fy, (0.021*E/d_t + Fy)*S, 0.33*E*S/d_t)\n",
    "            \n",
    "        # V        \n",
    "        Vd = 0.9 * 0.78*E/(d_t**(3/2)) * A/2\n",
    "\n",
    "    # Wide Flange Feasibility\n",
    "    if sec[0] == (\"W\"):\n",
    "        A=sec_info[\"W\"].A[sec]\n",
    "        Ix=sec_info[\"W\"].Ix[sec]\n",
    "        Iy=sec_info[\"W\"].Iy[sec]\n",
    "        Zx=sec_info[\"W\"].Zx[sec]\n",
    "        Zy=sec_info[\"W\"].Zy[sec]\n",
    "        D=sec_info[\"W\"].d[sec]\n",
    "        Sx=sec_info[\"W\"].Sx[sec]\n",
    "        d=sec_info[\"W\"].d[sec]\n",
    "        b_t=sec_info[\"W\"].b_t[sec] #bf/2tf (half the flange width over the flange thickness)\n",
    "        tf=sec_info[\"W\"].tf[sec]\n",
    "        tw=sec_info[\"W\"].tw[sec]\n",
    "        bf=sec_info[\"W\"].bf[sec]\n",
    "        h_tw=sec_info[\"W\"].h_tw[sec]\n",
    "        J=sec_info[\"W\"].J[sec]\n",
    "        rts=sec_info[\"W\"].rts[sec]\n",
    "        rx=sec_info[\"W\"].rx[sec]\n",
    "        ry=sec_info[\"W\"].ry[sec]        \n",
    "    \n",
    "        #Pc\n",
    "        Q = 1.0\n",
    "        if sec_info[\"W\"].CF_s[sec] == \"NS\":\n",
    "            if b_t <= 0.56*sqrt(E/Fy):\n",
    "                Q = 1.0\n",
    "            elif b_t > 0.56*sqrt(E/Fy) and b_t < 1.03*sqrt(E/Fy):\n",
    "                Q = 1.415 - 0.74*b_t*sqrt(Fy/E)\n",
    "            else:\n",
    "                Q = 0.69*E/(Fy*b_t**2)\n",
    "                \n",
    "        fe=np.pi**2*E/(K*l/r)**2\n",
    "        if (Q*Fy/fe)<=2.25:\n",
    "            fcr=Q*Fy*[0.658]**(Q*Fy/fe)\n",
    "        else:\n",
    "            fcr=0.877*fe\n",
    "        pc=(fcr*a)*0.9\n",
    "    \n",
    "        # Mcx\n",
    "        Cb = 1.0\n",
    "        Lp = 1.76*ry*sqrt(E/Fy)\n",
    "        h0 = d-tf\n",
    "        Lr = 1.95*rts*E/(0.7*Fy)*sqrt( J/(Sx*h0) + sqrt( (J/(Sx*h0))**2 + 6.76*(0.7*Fy/E)**2) )\n",
    "        Sxc = Sxt = 4*bf*(tf**3)/(3*d) + 2*bf*tf*d - 2*bf*(tf**2)\n",
    "        lamda = bf/(2*tf)\n",
    "        lamda_pf = 0.38*sqrt(E/Fy)\n",
    "        lamda_rf = sqrt(E/Fy)\n",
    "        \n",
    "        # AISC Section F2 - compact flanges and web\n",
    "        if sec_info[\"W\"].FF_s[sec] == \"C\" and sec_info[\"W\"].FW_s[sec] == \"C\":       \n",
    "            if (l <= Lp):\n",
    "                mcx = 0.9*Fy*Zx\n",
    "            elif (l > Lp and l <= Lr):\n",
    "                mp = Fy*Zx\n",
    "                mcx = 0.9* min(mp, Cb*(mp - (mp-0.7*Fy*Sx)*(l-Lp)/(Lr-Lp)))\n",
    "            else:\n",
    "                mp = Fy*Zx\n",
    "                mcx = 0.9* min(mp, Sx* Cb*np.pi()**2*E/((Lb/rts)**2) * sqrt(1+ 0.078*J/(Sx*h0)*(Lb/rts)**2))\n",
    "        \n",
    "        # AISC Section F3 - non-compact or slender flanges, and compact web\n",
    "        elif (sec_info[\"W\"].FF_s[sec] == \"NC\" or sec_info[\"W\"].FF_s[sec] == \"S\") and sec_info[\"W\"].FW_s[sec] == \"C\":\n",
    "            if (sec_info[\"W\"].FF_s[sec] == \"NC\"):\n",
    "                mp = Fy*Zx\n",
    "                mcx = 0.9* (mp-(mp-0.7*Fy*Sx)*(lamda-lamda_pf)/(lamda_rf-lamda_pf))       \n",
    "            elif (sec_info[\"W\"].FF_s[sec] == \"S\"):\n",
    "                kc = min(max(4/sqrt(h_tw), 0.35),0.76)\n",
    "                mcx = 0.9* 0.9*E*kc*Sx/(lamda**2)\n",
    "        \n",
    "        # AISC Section F4 - non-compact web\n",
    "        elif sec_info[\"W\"].FW_s[sec] == \"NC\":\n",
    "            return\n",
    "            # No such case in our design - will handle if needed\n",
    "        \n",
    "        # AISC Section F5 - slender web\n",
    "        elif sec_info[\"W\"].FW_s[sec] == \"S\":\n",
    "            return\n",
    "            # No such case in our design - will handle if needed\n",
    "            \n",
    "        # Mcy\n",
    "        if sec_info[\"W\"].FW_s[sec] == \"C\":\n",
    "            mcy = 0.9* min(Fy*Zy, 1.6*Fy*Sy)\n",
    "        elif sec_info[\"W\"].FW_s[sec] == \"NC\":\n",
    "            mp = min(Fy*Zy, 1.6*Fy*Sy)\n",
    "            mcy = 0.9 * (mp - (mp - 0.7*Fy*Sy)*(lamda-lamda_pf)/(lamda_rf-lamda_pf))\n",
    "        elif sec_info[\"W\"].FW_s[sec] == \"S\":\n",
    "            mcy = 0.9* 0.69*E/(b_t**2)*Sy\n",
    "                    \n",
    "        # V\n",
    "        Cv = 1\n",
    "        kv = 5\n",
    "        if h_tw > 1.1*sqrt(kv*E/Fy) and h_tw <= 1.37*sqrt(kv*E/Fy):\n",
    "            Cv = 1.1*sqrt(kv*E/Fy)/h_tw\n",
    "        elif h_tw > 1.37*sqrt(kv*E/Fy):\n",
    "            Cv = 1.51*kv*E/((h_tw**2)*Fy)\n",
    "            \n",
    "        Vd = 0.9* 0.6*Fy*(d-2*tf)*tw*Cv\n",
    "\n",
    "    # strength check\n",
    "    if (pr/pc)>=0.2:\n",
    "        util=pr/pc+8.0/9.0*(mrx/mcx+mry/mcy) \n",
    "    else:\n",
    "        util=pr/(2.0*pc)+(mrx/mcx+mry/mcy)\n",
    "       \n",
    "    #feasibility return\n",
    "    if util<=0.95: \n",
    "        return 1,pc,mcx,mcy,util\n",
    "    else: \n",
    "        return 0,pc,mcx,mcy,util\n",
    "\n",
    "\n",
    "# In[2]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## Import  data \n",
    "# \n",
    "# ##### read_member_data:\n",
    "# Read data, eleminate member information according the constraint tree, select necessary features.\n",
    "# \n",
    "# ##### read_section_data:\n",
    "# Read data, convert units,select necessary features.\n",
    "\n",
    "# In[184]:\n",
    "\n",
    "def read_section_data():\n",
    "    global num_all_sec\n",
    "    #import section_price\n",
    "    #sec_price=pd.read_csv('section_price.txt',sep=',', encoding='utf-16')\n",
    "    # read the section catalog\n",
    "    sec_info_W = pd.read_csv('W.txt',sep=',')\n",
    "    sec_info_HSS = pd.read_csv('HSS.txt',sep=',')\n",
    "    #sec_info_W = pd.merge(sec_info,sec_price).drop_duplicates().reset_index(drop=True)\n",
    "     \n",
    "    A=np.array(sec_info_W.A)\n",
    "    Ix=np.array(sec_info_W['Ix / 106'])*10**6\n",
    "    Iy=np.array(sec_info_W['Iy / 106'])*10**6\n",
    "    Zx=np.array(sec_info_W['Zx / 103'])*10**3\n",
    "    Zy=np.array(sec_info_W['Zy / 103'])*10**3\n",
    "    d = np.array(sec_info_W['d'])\n",
    "    b_t = np.array(sec_info_W['b/t'])\n",
    "    bf = np.array(sec_info_W['bf'])\n",
    "    tf = np.array(sec_info_W['tf'])\n",
    "    tw = np.array(sec_info_W['tw'])\n",
    "    h_tw = np.array(sec_info_W['h/tw'])\n",
    "    Sx = np.array(sec_info_W['Sx / 103'])*10**3\n",
    "    J = np.array(sec_info_W['J / 103'])*10**3\n",
    "    rts = np.array(sec_info_W['rts'])\n",
    "    rx = np.array(sec_info_W['rx'])\n",
    "    ry = np.array(sec_info_W['ry'])\n",
    "    C_flange = np.array(sec_info_W['Flange Compression'])\n",
    "    C_web = np.array(sec_info_W['Web Compression'])\n",
    "    F_flange = np.array(sec_info_W['Flange Flexure'])\n",
    "    F_web = np.array(sec_info_W['Web Flexure'])\n",
    "    \n",
    "    # old name: AISC_Manual_Label [metric] - check code for label changes\n",
    "    sec_info_W=pd.DataFrame({'AISC_W_Data [metric]':sec_info_W[\"AISC_Manual_Label\"],'FW_s':F_web, \\\n",
    "                             'FF_s':F_flange,'CW_s':C_web,'CF_s':C_flange,\\\n",
    "                             'tw':tw,'tf':tf,'rx':rx, \"ry\":ry, 'd':d,'b/t':b_t,'bf':bf,'h/tw':h_tw,\\\n",
    "                             'Sx':Sx,'J':J,'rts':rts,'Ix':Ix,'Iy':Iy,'Zx':Zx,'Zy':Zy,'A':A,'W':sec_info_W.W,\\\n",
    "                             'unit_price':sec_info_W.unit_price})\n",
    "    \n",
    "    A=np.array(sec_info_HSS.A)\n",
    "    I=np.array(sec_info_HSS['Ix / 106'])*10**6\n",
    "    Z=np.array(sec_info_HSS['Zx / 103'])*10**3\n",
    "    S = np.array(sec_info_HSS['Sx / 103'])*10**3\n",
    "    D = np.array(sec_info_HSS['OD'])\n",
    "    d_t = np.array(sec_info_HSS['D/t'])\n",
    "    r = np.array(sec_info_HSS['rx'])\n",
    "    C_slenderness = np.array(sec_info_HSS['Compression'])\n",
    "    F_slenderness = np.array(sec_info_HSS['Flexure'])\n",
    "    \n",
    "        \n",
    "    sec_info_HSS=pd.DataFrame({'AISC_HSS_Data [metric]':sec_info_HSS[\"AISC_Manual_Label\"],'F_s':F_slenderness,\\\n",
    "                               'C_s':C_slenderness,'r':r, 'd_t':d_t,'D':D,'I':I,'S':S,'Z':Z,'A':A,'W':sec_info_HSS.W,\\\n",
    "                               'unit_price':sec_info_HSS.unit_price})\n",
    "    sec_info= dict({\"W\":sec_info_W, \"HSS\":sec_info_HSS}) \n",
    "    # old sorting: [B,W] - clarify and check the code\n",
    "    sec_info[\"W\"]=sec_info_W.sort_values(['d','W'],ascending=True).set_index('AISC_W_Data [metric]')\n",
    "    sec_info[\"HSS\"]=sec_info_HSS.sort_values(['D','W'],ascending=True).set_index('AISC_HSS_Data [metric]')\n",
    "\n",
    "    num_all_sec = dict({\"W\":sec_info_W.count().A, \"HSS\":sec_info_HSS.count().A})\n",
    "    \n",
    "    return sec_info;\n",
    "\n",
    "\n",
    "def read_member_data():\n",
    "    global mem_info,contiuity_root,cycle_root,active_member_list\n",
    "    \n",
    "    def elimite_member_info(mem,elimite_root):\n",
    "        for i in range(len(mem['member_ID'])):\n",
    "            if mem['member_ID'][i] in elimite_root:\n",
    "                mem['member_ID'][i]=elimite_root[mem['member_ID'][i]]\n",
    "        return mem\n",
    "    \n",
    "    # read the member length\n",
    "    mem_geo=pd.read_csv('member_geometry.txt', encoding = 'utf-16')\n",
    "    #mem_geo=pd.read_csv('member_geometry.csv')#-----------\n",
    "    # read the governing forces\n",
    "    mem_force=pd.read_csv('SAP_O_MemberForce.txt',sep=',')\n",
    "    # combine the data\n",
    "    mem_info=pd.merge(mem_force,mem_geo).drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # calculate the DC-ratio manually\n",
    "    dummy_section='HSS63.5X6.4'\n",
    "    num_mem=mem_info.count().P\n",
    "    DC_manual=np.zeros(num_mem)\n",
    "    \n",
    "    for i in range(num_mem):\n",
    "        mem_id=mem_info.index[i]\n",
    "        (feasibility,pc,mcx,mcy,util)=check_feasibility(mem_id,dummy_section,3)\n",
    "        DC_manual[i]=util\n",
    "    mem_info['DC_Ratio_manual']=DC_manual\n",
    "    \n",
    "    # drop the duplicated\n",
    "    mem_info=mem_info.sort_values(by=['member_ID','DC_Ratio_manual'],                                          ascending=[True,False]).drop_duplicates(subset=['member_ID'], keep='first').reset_index(drop=True)\n",
    "     \n",
    "    # elimite the number of member according to the continuity constraints\n",
    "    mem_info_compacted=mem_info.copy(deep=True)\n",
    "    mem_info_compacted=elimite_member_info(mem_info_compacted,continuity_root)\n",
    "    mem_info_compacted=elimite_member_info(mem_info_compacted,cycle_root)\n",
    "    mem_info_compacted=mem_info_compacted.sort_values(by=['member_ID','DC_Ratio_manual'],                                          ascending=[True,False]).drop_duplicates(subset=['member_ID'], keep='first').reset_index(drop=True)\n",
    "    #mem_info_compacted=organize_mem_info(mem_info_compacted)\n",
    "\n",
    "    Mx=abs(np.array(mem_info.Mx))\n",
    "    My=abs(np.array(mem_info.My))\n",
    "    P=abs(np.array(mem_info.P))\n",
    "    DC=abs(np.array(mem_info.DC_Ratio_manual))\n",
    "    L=np.array(mem_info.member_length)\n",
    "     \n",
    "    Mx_compacted=abs(np.array(mem_info_compacted.Mx))\n",
    "    My_compacted=abs(np.array(mem_info_compacted.My))\n",
    "    P_compacted=abs(np.array(mem_info_compacted.P))\n",
    "    DC_compacted=abs(np.array(np.array(mem_info_compacted.DC_Ratio_manual)))\n",
    "    L_compacted=np.array(mem_info_compacted.member_length)\n",
    "    \n",
    "    # aggregate the data\n",
    "    mem_info_compacted=pd.DataFrame({'member_ID':mem_info_compacted.member_ID,                                     'P': P_compacted,'Mx':Mx_compacted,'My':My_compacted,                                     'L':L_compacted,'group':mem_info_compacted.member_type,'DC':DC_compacted})\n",
    "    mem_info=pd.DataFrame({'member_ID':mem_info.member_ID,'P': P,'Mx':Mx,'My':My,                           'L':L,'group':mem_info.member_type,'DC':DC})\n",
    "    \n",
    "    mem_info=mem_info.set_index('member_ID')\n",
    "    mem_info_compacted=mem_info_compacted.set_index('member_ID')\n",
    "    active_member_list=mem_info_compacted.index\n",
    "    \n",
    "    return mem_info,mem_info_compacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Develop the tree\n",
    "# \n",
    "# ##### formulate_graph:\n",
    "# <code>Input:</code>\n",
    "# * con_pair: have two columns--column_A and column_B, each row is an edge, directed from column_A to column_B.\n",
    "# \n",
    "# <code>Output use two dictionary to describe the tree: </code>\n",
    "#     \n",
    "# * 'graph_children' saves the children for each node,\n",
    "# * 'graph_parents' saves the parents for each nodes.\n",
    "# \n",
    "# ##### find_union:\n",
    "# \n",
    "# <code>Input would be a graph,contains two maps: </code>\n",
    "# * one map saves the children for each node\n",
    "# * another map saves the parents for each node.\n",
    "# \n",
    "# <code>Output would be:</code>\n",
    "#     \n",
    "# * a map 'union' whose key is the union root and contents is the union set\n",
    "# * and a map 'root_union' that key is the children and contents is the union root.\n",
    "\n",
    "# In[181]:\n",
    "\n",
    "def formulate_graph(con_pair,column_A,column_B):\n",
    "    # initialization\n",
    "\n",
    "    graph_children={cr:[] for cr in con_pair[column_A]}\n",
    "    graph_parents={cr:[] for cr in con_pair[column_B]}\n",
    "    \n",
    "    # find the children and parents\n",
    "    for i in con_pair.index:\n",
    "        graph_children[con_pair[column_A][i]].append(con_pair[column_B][i])\n",
    "        graph_parents[con_pair[column_B][i]].append(con_pair[column_A][i])\n",
    "        \n",
    "    return graph_children,graph_parents\n",
    "\n",
    "\n",
    "# union find algorithm\n",
    "def find_union(graph_children,graph_parents):\n",
    "    union={}\n",
    "    parents={}\n",
    "    root_union={}  \n",
    "    \n",
    "    # set the parent of each node as itself\n",
    "    def initial_it():\n",
    "        parents={}\n",
    "        for node in graph_children:\n",
    "            parents[node]=node\n",
    "        for node in graph_parents:\n",
    "            parents[node]=node\n",
    "        return parents\n",
    "    \n",
    "    # set the parent of y pointed to the parent of x\n",
    "    def union_it(x,y):\n",
    "        p_x=find_root(x)\n",
    "        p_y=find_root(y)\n",
    "        parents[p_y]=p_x;\n",
    "        \n",
    "    # recursivelt find the root, \n",
    "    # if the parent of a node is itself, then it is the root\n",
    "    def find_root(node):\n",
    "        if node != parents[node]:\n",
    "            return find_root(parents[node])\n",
    "        else:\n",
    "            return node\n",
    "      \n",
    "    parents=initial_it();\n",
    "    \n",
    "    for node in graph_children:\n",
    "        for c_node in graph_children[node]:\n",
    "            union_it(node,c_node);\n",
    "                    \n",
    "    for node in parents:\n",
    "        r_node=find_root(node);\n",
    "        if r_node not in union:\n",
    "            union[r_node]=[node];\n",
    "        else:\n",
    "            union[r_node].append(node);\n",
    "        root_union[node]=r_node; \n",
    "    \n",
    "    return union,root_union\n",
    "\n",
    "\n",
    "# ## Find cycle in the graph\n",
    "#   \n",
    "# Tarjan's Algorithm (named for its discoverer, Robert Tarjan) is a graph theory algorithm\n",
    "# for finding the strongly connected components of a graph.\n",
    "#     \n",
    "# Based on: http://en.wikipedia.org/wiki/Tarjan%27s_strongly_connected_components_algorithm\n",
    "#     \n",
    "# <code>Input for this function is a map:</code>\n",
    "# * whose key is each node and contents are its children\n",
    "#     \n",
    "# <code>Output includes two maps:</code>\n",
    "# * cycle_list: whose keys are root for each strongly connected components, and contents are the nodes in this component.\n",
    "# * root_cycle: whose keys are nodes in the strongly connected components, and contents are the roots for that node.\n",
    "#  \n",
    "#  \n",
    "\n",
    "def strongly_connected_components(graph):\n",
    "  \n",
    "    index_counter = [0]\n",
    "    stack = []\n",
    "    lowlinks = {}\n",
    "    index = {}\n",
    "    result = []\n",
    "    \n",
    "    def strongconnect(node):\n",
    "        # set the depth index for this node to the smallest unused index\n",
    "        index[node] = index_counter[0]\n",
    "        lowlinks[node] = index_counter[0]\n",
    "        index_counter[0] += 1\n",
    "        stack.append(node)\n",
    "    \n",
    "        # Consider successors of `node`\n",
    "        try: \n",
    "            successors = graph[node]\n",
    "        except:\n",
    "            successors = []\n",
    "        for successor in successors:\n",
    "            if successor not in lowlinks:\n",
    "                # Successor has not yet been visited; recurse on it\n",
    "                strongconnect(successor)\n",
    "                lowlinks[node] = min(lowlinks[node],lowlinks[successor])\n",
    "            elif successor in stack:\n",
    "                # the successor is in the stack and hence in the current strongly connected component (SCC)\n",
    "                lowlinks[node] = min(lowlinks[node],index[successor])\n",
    "        \n",
    "        # If `node` is a root node, pop the stack and generate an SCC\n",
    "        if lowlinks[node] == index[node]:\n",
    "            connected_component = []\n",
    "            \n",
    "            while True:\n",
    "                \n",
    "                successor = stack.pop()\n",
    "                connected_component.append(successor)\n",
    "                if successor == node: break\n",
    "            component = tuple(connected_component)\n",
    "            # storing the result\n",
    "            result.append(component)\n",
    "    \n",
    "    for node in graph:\n",
    "        if node not in lowlinks:\n",
    "            strongconnect(node)\n",
    "    \n",
    "    result=[r for r in result if len(r)>1]\n",
    "    \n",
    "    # make it to a map\n",
    "    cycle_list={}\n",
    "    root_cycle={}\n",
    "    for lists in result:\n",
    "        cycle_list[lists[0]]=lists\n",
    "        for element in lists:\n",
    "            root_cycle[element]=lists[0]\n",
    " \n",
    "    return cycle_list,root_cycle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Topological ordering\n",
    "# Use a deep first search algorithm to decide the topological sorting. This algorithm is capable to handle the situation that some nodes are isolated from the tree. The algorithm is described here  https://en.wikipedia.org/wiki/Topological_sorting\n",
    "# \n",
    "# \n",
    "# <code>Input for this function is a map:</code>\n",
    "# * whose key is each node and contents are its children\n",
    "#     \n",
    "# <code>Output:</code>\n",
    "# * The priority list\n",
    "\n",
    "# In[183]:\n",
    "\n",
    "## Topological sorting\n",
    "# This part I use DFS to calculate the topological sortting for the constriant tree\n",
    "# To implement this, a global variable queue is used for saves the order of finished nodes.\n",
    "\n",
    "GRAY, BLACK = 0, 1\n",
    "\n",
    "def topological(graph):\n",
    "    order, enter, state = deque(), set(graph), {}\n",
    "\n",
    "    def dfs(node):\n",
    "        state[node] = GRAY\n",
    "        for k in graph.get(node, ()):\n",
    "            sk = state.get(k, None)\n",
    "            if sk == GRAY: raise ValueError(\"cycle\")\n",
    "            if sk == BLACK: continue\n",
    "            enter.discard(k)\n",
    "            dfs(k)\n",
    "        order.appendleft(node)\n",
    "        state[node] = BLACK\n",
    "\n",
    "    while enter: dfs(enter.pop())\n",
    "    return order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## Pre-Processing\n",
    "\n",
    "# In[240]:\n",
    "\n",
    "# fomulate continuity member set\n",
    "contin_pair=pd.read_csv('continuity_constraints_list.txt',index_col=0)\n",
    "if (contin_pair.empty):\n",
    "    contin_pair=pd.read_csv('continuity_constraints_list.txt')\n",
    "[conti_children,conti_parents]=formulate_graph(contin_pair,'Member_A','Member_B')\n",
    "[continuity_list,continuity_root]=find_union(conti_children,conti_parents)\n",
    "\n",
    "# fomulate the graph for constraints\n",
    "cons_pair=pd.read_csv('hierarchical_constraints_list.txt',index_col=0)\n",
    "if (cons_pair.empty):\n",
    "    cons_pair=pd.read_csv('hierarchical_constraints_list.txt')\n",
    "cons_pair=merging_and_removing_constraint(cons_pair,continuity_root)\n",
    "[graph_children,graph_parents]=formulate_graph(cons_pair,'Larger','Smaller')\n",
    "#cons_pair=cons_pair.reset_index(drop=True)\n",
    "\n",
    "# find the cycle in the graph\n",
    "[cycle_list,cycle_root]=strongly_connected_components(graph_children)\n",
    "cons_pair=merging_and_removing_constraint(cons_pair,cycle_root)\n",
    "[graph_children,graph_parents]=formulate_graph(cons_pair,'Larger','Smaller')\n",
    "\n",
    "# read the data\n",
    "sec_info=read_section_data();\n",
    "[mem_info,mem_info_compacted]=read_member_data();\n",
    "\n",
    "\n",
    "# topological sorting\n",
    "priority_list=topological(graph_children)\n",
    "# find the isolated ones\n",
    "for aml in active_member_list:\n",
    "    if aml not in priority_list:\n",
    "        priority_list.append(aml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In[180]:\n",
    "\n",
    "# Assume that each member will only appears at most once in the continuity_list file \n",
    "\n",
    "# ## Algorithm for determining the cross section for each member\n",
    "# \n",
    "# This part include 3 small sections:\n",
    "# ##### The first level -- find_optimal_section_for_structure: \n",
    "# * Find the optimal section size according to the order of priority list\n",
    "# * Call 'find_upper_bound'to Find the cross section upper bound of a member according the constraint tree.\n",
    "# * Call 'find_optimal_section_for_member' to find the smalllest section for each member\n",
    "# * update the DataFrame 'cs'\n",
    "# * output: the DataFrame: 'cs'\n",
    "# \n",
    "# ##### The second level -- find_optimal_section_for_structure: \n",
    "# * Input: member id, cross section upper bound, cross section lower bound\n",
    "# * Sorting the member according to 'Zx\\*Mry+Zy\\*Mrx', and slicing the dataframe accoridng to upper bound and lower bound\n",
    "# * Use binary search to find the feasible-infeasible point.(Call function 'check_feasibility')\n",
    "# * If the upper bound is not larger enough, then relax upper bound, and recall the function 'find_optimal_section_for_structure'. And then call the 'back_jumping_updating' to update the cross section of its parents.\n",
    "# * Output: the smallest section for the specific member\n",
    "# \n",
    "# ##### The Third level -- check_feasibility: \n",
    "# * Input: The member id, and the cross section\n",
    "# * output: feasibility, pc, mcx,mcy\n",
    "\n",
    "# In[205]:\n",
    "\n",
    "# part 1: FUNCTION -- Loop through all the members\n",
    "def find_optimal_section_for_structure(): \n",
    "    global cs\n",
    "    global priority_list\n",
    "    \n",
    "    cs=pd.DataFrame({'member_ID':[],'cross_section':[],'feasibility':[],'Pc':[],'Mcx':[],'Mcy':[]}).set_index('member_ID')\n",
    "    num_member=len(priority_list)\n",
    "    \n",
    "    for ind in range(num_member):\n",
    "        # part 1.1 :looping over the priority list\n",
    "        mem_id=priority_list[ind]\n",
    "        \n",
    "        if mem_id in active_member_list:\n",
    "            \n",
    "            upper_bound_cs=find_upper_bound(mem_id);\n",
    "\n",
    "            # part 1.2 : find the optimal section size\n",
    "            (s,f,pc,mcx,mcy,util)=find_optimal_section_for_member(mem_id,upper_bound_cs)\n",
    "            cs_new=pd.DataFrame({'member_ID':mem_id,'cross_section':s,'feasibility':f,'Pc':pc,'Mcx':mcx,'Mcy':mcy,'util':util},index=[mem_id]).set_index('member_ID')\n",
    "            cs=cs.append(cs_new) \n",
    "        \n",
    "# this returns an cross section (e.g. HSS406.4X406.4X15.9) that sets the upper bond size for argument index\n",
    "def find_upper_bound(mem_id):\n",
    "    global graph_parents,sec_info\n",
    "    global cs\n",
    "    \n",
    "    if mem_info_compacted['group'][mem_id] == 3:\n",
    "        return sec_info['HSS'].index[-1]\n",
    "    \n",
    "    upper_bound_cs=sec_info['W'].index[-1]\n",
    "    if mem_id in graph_parents: # if mem_id has parents\n",
    "        for pa_id in graph_parents[mem_id]: # for each parent\n",
    "            if pa_id in active_member_list:\n",
    "                pa_cs=cs.cross_section[pa_id]; # find its cross section\n",
    "                \"\"\"This takes care of both web-flange and flange-flange connections, \n",
    "                    needs to be fixed after the member orientation info added\"\"\"\n",
    "                if (sec_info['W'].d[upper_bound_cs]>sec_info['W'].d[pa_cs] - 2*sec_info['W'].tf[pa_cs] \\\n",
    "                    or sec_info['W'].bf[upper_bound_cs]>info_['W'].bf[pa_cs]): # find the smallest width of the parents' cross section\n",
    "                    upper_bound_cs=pa_cs\n",
    "                \n",
    "    return upper_bound_cs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'b_t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-307e6f0dc386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m# assign each member a cross section\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mfind_optimal_section_for_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mmapping_back_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcycle_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0mmapping_back_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontinuity_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-bbac336570cd>\u001b[0m in \u001b[0;36mfind_optimal_section_for_structure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# part 1.2 : find the optimal section size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmcx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmcy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_optimal_section_for_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupper_bound_cs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mcs_new\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'member_ID'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmem_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cross_section'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'feasibility'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Pc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Mcx'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmcx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Mcy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmcy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'util'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmem_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'member_ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-307e6f0dc386>\u001b[0m in \u001b[0;36mfind_optimal_section_for_member\u001b[0;34m(mem_id, upper_bound_cs, lower_bound_cs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnew_sec_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_choice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mfeasibility\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmcx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmcy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_feasibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msec_info_sliced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_sec_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeasibility\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-fae5c23e91cb>\u001b[0m in \u001b[0;36mcheck_feasibility\u001b[0;34m(mem_id, sec, flag)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mSx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msec_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msec_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mb_t\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msec_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#bf/2tf (half the flange width over the flange thickness)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msec_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msec_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'b_t'"
     ]
    }
   ],
   "source": [
    "# part 2: FUNCTION -- randomized Binary search to find the feasible - infeasible point\n",
    "def find_optimal_section_for_member(mem_id,upper_bound_cs=None,lower_bound_cs=None):\n",
    "    global sec_info,mem_info_compacted,num_all_sec\n",
    "    \n",
    "    if mem_info_compacted.group[mem_id]==3:\n",
    "        sec_type=\"HSS\"\n",
    "    else:\n",
    "        sec_type=\"W\"\n",
    "    \n",
    "    if upper_bound_cs is None:    \n",
    "        upper_bound_cs= sec_info[sec_type].index[-1]\n",
    "                                               \n",
    "    if lower_bound_cs is None:\n",
    "\n",
    "        lower_bound_cs= sec_info[sec_type].index[0]\n",
    "\n",
    "    # we first sort the section accoridng to area, and then find the smallest section that makes it feasible\n",
    "    sec_info_sliced=(sec_info[sec_type].loc[lower_bound_cs:upper_bound_cs]).sort_values(by='A',ascending=True)\n",
    "    \n",
    "    num_choice=sec_info_sliced.count().A\n",
    "\n",
    "    # the determinist way\n",
    "    for new_sec_ind in range(0,num_choice):\n",
    "\n",
    "        (feasibility,pc,mcx,mcy,util)=check_feasibility(mem_id,sec_info_sliced.index[new_sec_ind],1)\n",
    "        if feasibility==1:\n",
    "            break;\n",
    "            \n",
    "    optimal_cs=sec_info_sliced.index[new_sec_ind]\n",
    "        \n",
    "    # back_jumping part\n",
    "    if feasibility!=1 and num_choice!=num_all_sec[sec_type]:\n",
    "        #print ('back_jumping **',mem_id)\n",
    "        (optimal_cs,feasibility,pc,mcx,mcy,util)=find_optimal_section_for_member(mem_id);\n",
    "        back_jumping_updating(mem_id,optimal_cs)\n",
    "\n",
    "    return (optimal_cs,feasibility,pc,mcx,mcy,util) # return the index\n",
    "\n",
    "def back_jumping_updating(mem_id,sec):\n",
    "    global cs,sec_info\n",
    "    global graph_parents\n",
    "    \n",
    "    if mem_info_compacted.group[mem_id]==3:\n",
    "        sec_type=\"HSS\"\n",
    "    else:\n",
    "        sec_type=\"W\"\n",
    "    \n",
    "    if mem_id in cs.index:   # mem_id has been assigned before\n",
    "        if sec_info[sec_type].B[sec]>sec_info[sec_type].B[cs.cross_section[mem_id]] : # the children node has larger cross section\n",
    "            (feasibility,pc,mcx,mcy,util)=check_feasibility(mem_id,sec,1)\n",
    "            if feasibility !=1:\n",
    "               (sec,feasibility,pc,mcx,mcy,util)=find_optimal_section_for_member(mem_id,sec_info[sec_type].index[-1],sec)\n",
    "    \n",
    "            cs.feasibility[mem_id]=feasibility\n",
    "            cs.cross_section[mem_id]=sec\n",
    "            cs.Pc[mem_id]=pc\n",
    "            cs.Mcx[mem_id]=mcx\n",
    "            cs.Mcy[mem_id]=mcy            \n",
    "            #print ('bj',mem_id,' updated section size',sec)\n",
    "        \n",
    "    if mem_id in graph_parents: # mem_id is not a root node, then find its parents\n",
    "        #print('bj, find par',mem_id)\n",
    "        for mem_pa in graph_parents[mem_id]:\n",
    "            back_jumping_updating(mem_pa,sec);\n",
    "\n",
    "# In[207]:\n",
    "\n",
    "def calculate_cost():\n",
    "    global mem_info,sec_info\n",
    "    member_cost=[]\n",
    "    for i in mem_info.index:\n",
    "        size=mem_info.cross_section[i]\n",
    "        c=sec_info.unit_price[size]*sec_info.W[size]*mem_info.L[i]/1000000 \n",
    "        # if the W is N/mm. L is mm... check this unit assumption!!!!!!!!!!!????\n",
    "        member_cost.append(c)\n",
    "\n",
    "    return member_cost\n",
    "\n",
    "def calculate_load_per_unit_cost():\n",
    "    global mem_info,sec_info\n",
    "    \n",
    "    member_lpuc=[]\n",
    "    for i in mem_info.index:\n",
    "        \n",
    "        if mem_info_compacted.group[i]==3:\n",
    "            sec_type=\"HSS\"\n",
    "        else:\n",
    "            sec_type=\"W\"\n",
    "            \n",
    "        size=mem_info.cross_section[i]\n",
    "        p1=mem_info.P[i]/sec_info.A[size]+(mem_info.Mx[i]*sec_info[sec_type].B[size]/sec_info[sec_type].Ix[size]/2 \\\n",
    "                                           +mem_info.My[i]*sec_info[sec_type].B[size]/sec_info[sec_type].Iy[size]/2)\n",
    "        p2=mem_info.Mx[i]/mem_info.Mcx[i]+mem_info.My[i]/mem_info.Mcy[i]\n",
    "        \n",
    "        #lpuc=(mem_info.P[i]/(mem_info.Pc[i]*p1*sec_info.A[size]))+(p2/(p1*sec_info.Ix[size]))\n",
    "        lpuc = ((mem_info.P[i]/sec_info.A[size]) + (sec_info[sec_type].B[size]/(sec_info.Ix[size]*2.0)) \\\n",
    "                * (mem_info.My[i] + mem_info.Mx[i])) * sec_info[sec_type].A[size]/1e20\n",
    "        # if the W is kg/m. L is mm... check this unit assumption!!!!!!!!!!!????\n",
    "        member_lpuc.append(lpuc)\n",
    "\n",
    "    return member_lpuc\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "# ## Main Fucntion\n",
    "\n",
    "# assign each member a cross section\n",
    "find_optimal_section_for_structure()\n",
    "mapping_back_group(cycle_list)\n",
    "mapping_back_group(continuity_list)\n",
    "cs.index.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# aggregate all the features\n",
    "mem_info['cross_section']=cs.cross_section\n",
    "mem_info['feasibility']=cs.feasibility\n",
    "mem_info['Pc']=cs.Pc\n",
    "mem_info['Mcx']=cs.Mcx\n",
    "mem_info['Mcy']=cs.Mcy\n",
    "mem_info['util']=cs.util\n",
    "mem_info['cost']=calculate_cost()\n",
    "mem_info['load_per_unit_cost']=calculate_load_per_unit_cost()\n",
    "\n",
    "\n",
    "# ## Output all the data\n",
    "\n",
    "# In[243]:\n",
    "\n",
    "# export the data to exele\n",
    "Member_ID=mem_info.index\n",
    "mem_size_for_file=pd.DataFrame({'member_ID': mem_info.index,'cross_section':mem_info.cross_section}).set_index('member_ID')\n",
    "mem_lpuc_for_file=pd.DataFrame({'member_ID': mem_info.index,'load_inverse':mem_info.load_per_unit_cost}).set_index('member_ID')\n",
    "mem_cost_for_file=pd.DataFrame({'member_ID': mem_info.index,'cost':mem_info.cost}).set_index('member_ID')\n",
    "mem_util_for_file=pd.DataFrame({'member_ID': mem_info.index,'util':mem_info.util}).set_index('member_ID')\n",
    "\n",
    "mem_size_for_file.to_csv('member_sectionSizes.txt')\n",
    "mem_lpuc_for_file.to_csv('member_load_inverse.txt')\n",
    "mem_cost_for_file.to_csv('member_cost.txt')\n",
    "mem_util_for_file.to_csv('member_feasibility.txt')\n",
    "\n",
    "membGeomFile.close()\n",
    "membForcesFile.close()\n",
    "continConsFile.close()\n",
    "hierConsFile.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
